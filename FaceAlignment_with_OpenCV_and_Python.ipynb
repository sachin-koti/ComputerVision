{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceAlignment_with_OpenCV_and_Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of facial landmarks (the input coordinates) our goal is to warp and transform the image to an output coordinate space.\n",
    "\n",
    "In this output coordinate space, all faces across an entire dataset should:\n",
    "- 1) Be centered in the image.\n",
    "- 2) Be rotated that such the eyes lie on a horizontal line (i.e., the face is rotated such that the eyes lie along the same y-coordinates).\n",
    "- 3) Be scaled such that the size of the faces are approximately identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_utils import FACIAL_LANDMARKS_IDXS, shape_to_np\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceAligner:\n",
    "    def __init__(self, predictor, desiredLeftEye=(0.35, 0.35), desiredFaceWidth=256, desiredFaceHeight=None):\n",
    "        # store the facial landmark predictor, desired output left\n",
    "        # eye position, and desired output face width + height\n",
    "        self.predictor = predictor\n",
    "        self.desiredLeftEye = desiredLeftEye\n",
    "        self.desiredFaceWidth = desiredFaceWidth\n",
    "        self.desiredFaceHeight = desiredFaceHeight\n",
    "        \n",
    "        # if the desired face height is None, set it to be the\n",
    "        # desired face width (normal behavior)\n",
    "        if desiredFaceHeight is None:\n",
    "            self.desiredFaceHeight = self.desiredFaceWidth\n",
    "    \n",
    "    def align(self, image, gray, rect):\n",
    "         # convert the landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = self.predictor(gray, rect)\n",
    "        shape = shape_to_np(shape)\n",
    "        \n",
    "        # extract the left and right eye (x, y)-coordinates\n",
    "        (lStart, lEnd) = FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "        (rStart, rEnd) = FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "        leftEyePts = shape[lStart:lEnd]\n",
    "        rightEyePts = shape[rStart:rEnd]\n",
    "        \n",
    "        # compute the center of mass for each eye\n",
    "        leftEyeCenter = leftEyePts.mean(axis = 0).astype(\"int\")\n",
    "        rightEyeCenter = rightEyePts.mean(axis = 0).astype(\"int\")\n",
    "        \n",
    "        # compute the angle between the eye centroids\n",
    "        dY = rightEyeCenter[1] - leftEyeCenter[1]\n",
    "        dX = rightEyeCenter[0] - leftEyeCenter[0]\n",
    "        angle = np.degrees(np.arctan2(dY, dX)) - 180\n",
    "        \n",
    "        # compute the desired right eye x-coordinate based on the\n",
    "        # desired x-coordinate of the left eye\n",
    "        desiredRightEyeX = 1.0 - self.desiredLeftEye[0]\n",
    "        \n",
    "        # determine the scale of the new resulting image by taking\n",
    "        # the ratio of the distance between eyes in the *current*\n",
    "        # image to the ratio of distance between eyes in the *desired* image\n",
    "        dist = np.sqrt((dX ** 2) + (dY ** 2))\n",
    "        desiredDist = (desiredRightEyeX - self.desiredLeftEye[0])\n",
    "        desiredDist *= self.desiredFaceWidth    #This essentially scales our eye distance based on the desired width.\n",
    "        scale = desiredDist / dist\n",
    "        \n",
    "        # compute center (x, y)-coordinates (i.e., the median point)\n",
    "        # between the two eyes in the input image\n",
    "        eyesCenter = ((leftEyeCenter[0] + rightEyeCenter[0]) // 2, (leftEyeCenter[1] + rightEyeCenter[1]) // 2)\n",
    "        \n",
    "        # grab the rotation matrix for rotating and scaling the face\n",
    "        M = cv2.getRotationMatrix2D(eyesCenter, angle, scale)\n",
    "        \n",
    "        # update the translation component of the matrix\n",
    "        tX = self.desiredFaceWidth * 0.5\n",
    "        tY = self.desiredFaceHeight * self.desiredLeftEye[1]\n",
    "        M[0, 2] += (tX - eyesCenter[0])\n",
    "        M[1, 2] += (tY - eyesCenter[1])\n",
    "        \n",
    "        # apply the affine transformation\n",
    "        (w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n",
    "        output = cv2.warpAffine(image, M, (w, h), flags = cv2.INTER_CUBIC)\n",
    "        \n",
    "        # return the aligned face\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given the eye centers, we can compute differences in (x, y)-coordinates and take the arc-tangent to obtain angle of rotation between eyes.\n",
    "- we calculate the desired right eye based upon the desired left eye x-coordinate. We subtract __self.desiredLeftEye[0]__  from 1.0  because the __desiredRightEyeX__  value should be equidistant from the right edge of the image as the corresponding left eye x-coordinate is from its left edge.\n",
    "- __M__ : The translation, rotation, and scaling matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_utils import rect_to_bb\n",
    "import dlib\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor and the face aligner\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=256)\n",
    "\n",
    "# load the input image, resize it, and convert it to grayscale\n",
    "image = cv2.imread(\"IMG_20170123_182237284.jpg\")\n",
    "image = imutils.resize(image, width = 800)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# show the original input image and detect faces in the grayscale image\n",
    "cv2.imshow(\"Input\", image)\n",
    "rects = detector(gray, 2)\n",
    "\n",
    "for rect in rects:\n",
    "    (x, y, w, h) = rect_to_bb(rect)\n",
    "    faceOrig = imutils.resize(image[y:y + h, x:x + w], width = 256)\n",
    "    faceAligned = fa.align(image, gray, rect)\n",
    "    \n",
    "    stacked = np.vstack((faceOrig, faceAligned))\n",
    "    #cv2.imshow(\"Original\", faceOrig)\n",
    "    #cv2.imshow(\"Aligned\", faceAligned)\n",
    "    cv2.imshow(\"Output\", stacked)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facial alignment is a normalization technique, often used to improve the accuracy of face recognition algorithms, including deep learning models.\n",
    "- The trick is determining the components of the transformation matrix, M .\n",
    "- Our facial alignment algorithm hinges on knowing the (x, y)-coordinates of the eyes.\n",
    "- Facial landmarks tend to work better than Haar cascades or HOG detectors for facial alignment since we obtain a more precise estimation to eye location (rather than just a bounding box)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
